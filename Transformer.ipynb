{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-29T16:35:29.719832Z",
     "iopub.status.busy": "2024-11-29T16:35:29.719540Z",
     "iopub.status.idle": "2024-11-29T16:35:30.884147Z",
     "shell.execute_reply": "2024-11-29T16:35:30.883143Z",
     "shell.execute_reply.started": "2024-11-29T16:35:29.719803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/poem-vn/new_data_clean2.csv\n",
      "/kaggle/input/poem-vn/start_vowels.txt\n",
      "/kaggle/input/poem-vn/tone_dict.txt\n",
      "/kaggle/input/poem-vn/rhymes.txt\n",
      "/kaggle/input/poem-vn/new_data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "# # Đọc dữ liệu\n",
    "# df = pd.read_csv('/kaggle/input/poem-vn/new_data_clean2.csv').head(10000)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:44:12.623299Z",
     "iopub.status.busy": "2024-11-30T04:44:12.622877Z",
     "iopub.status.idle": "2024-11-30T04:44:13.141960Z",
     "shell.execute_reply": "2024-11-30T04:44:13.140657Z",
     "shell.execute_reply.started": "2024-11-30T04:44:12.623256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import re\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "def is_vietnamese_word(word):\n",
    "    vietnamese_pattern = r'^[aàảãáạăằẳẵắặâầẩẫấậbcdđeèẻẽéẹêềểễếệfghiìỉĩíịjklmnoòỏõóọôồổỗốộơờởỡớợpqrstuùủũúụưừửữứựvwxyỳỷỹýỵz]+$'\n",
    "    return bool(re.match(vietnamese_pattern, word.lower()))\n",
    "\n",
    "def get_rhyme(word):\n",
    "    if not word or not is_vietnamese_word(word):\n",
    "        return ''\n",
    "    # Lấy âm cuối của từ\n",
    "    vowels = 'aàảãáạăằẳẵắặâầẩẫấậeèẻẽéẹêềểễếệiìỉĩíịoòỏõóọôồổỗốộơờởỡớợuùủũúụưừửữứựyỳỷỹýỵ'\n",
    "    word = word.lower()\n",
    "    rhyme = ''\n",
    "    for i in range(len(word)-1, -1, -1):\n",
    "        if word[i] in vowels:\n",
    "            rhyme = word[i:]\n",
    "            break\n",
    "    return rhyme\n",
    "\n",
    "def get_tone(word):\n",
    "    if not word or not is_vietnamese_word(word):\n",
    "        return 'neutral'\n",
    "    \n",
    "    even_tones = 'aăâeêioôơuưy' + 'àằầèềìòồờùừỳ' + 'ảẳẩẻểỉỏổởủửỷ'\n",
    "    uneven_tones = 'áắấéếíóốớúứý' + 'ạặậẹệịọộợụựỵ' + 'ãẵẫẽễĩõỗỡũữỹ'\n",
    "    \n",
    "    word = word.lower()\n",
    "    last_char = word[-1]\n",
    "    \n",
    "    if last_char in even_tones:\n",
    "        return 'even'\n",
    "    elif last_char in uneven_tones:\n",
    "        return 'uneven'\n",
    "    return 'neutral'\n",
    "\n",
    "class LucBatDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer.encode(text)\n",
    "        \n",
    "        input_ids = encoding.ids[:-1]\n",
    "        labels = encoding.ids[1:]\n",
    "        \n",
    "        padding_length = self.max_length - len(input_ids)\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + [self.tokenizer.token_to_id(\"[PAD]\")] * padding_length\n",
    "            labels = labels + [self.tokenizer.token_to_id(\"[PAD]\")] * padding_length\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids[:self.max_length]),\n",
    "            \"labels\": torch.tensor(labels[:self.max_length])\n",
    "        }\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class LucBatTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int = 512, nhead: int = 8, \n",
    "                 num_layers: int = 6, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, \n",
    "                                                  dim_feedforward=2048, \n",
    "                                                  dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        embedded = self.pos_encoder(embedded)\n",
    "        output = self.transformer_encoder(embedded)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc_out(output)\n",
    "        return output\n",
    "\n",
    "def create_tokenizer(texts: List[str]) -> Tokenizer:\n",
    "    tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "    \n",
    "    special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"\\n\"]\n",
    "    trainer = trainers.WordPieceTrainer(\n",
    "        vocab_size=12258, # láy trong token \n",
    "        special_tokens=special_tokens\n",
    "    )\n",
    "    \n",
    "    tokenizer.train_from_iterator(texts, trainer=trainer)\n",
    "    return tokenizer\n",
    "\n",
    "def train_epoch(model: nn.Module, dataloader: DataLoader, \n",
    "                optimizer: torch.optim.Optimizer, device: torch.device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Wrap DataLoader with tqdm to show progress\n",
    "    for batch in tqdm(dataloader, desc=\"Training\", unit=\"batch\"):  # Add tqdm here\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids)\n",
    "        outputs = outputs.view(-1, outputs.size(-1))\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def get_tone_type(word):\n",
    "    \"\"\"Phân loại thanh điệu của từ\"\"\"\n",
    "    vowels = {\n",
    "        'even': ['a', 'ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'i', 'u', 'ư', 'y',\n",
    "                'à', 'ằ', 'ầ', 'è', 'ề', 'ò', 'ồ', 'ờ', 'ì', 'ù', 'ừ', 'ỳ'],\n",
    "        'uneven': ['á', 'ắ', 'ấ', 'é', 'ế', 'ó', 'ố', 'ớ', 'í', 'ú', 'ứ', 'ý',\n",
    "                   'ạ', 'ặ', 'ậ', 'ẹ', 'ệ', 'ọ', 'ộ', 'ợ', 'ị', 'ụ', 'ự', 'ỵ',\n",
    "                   'ả', 'ẳ', 'ẩ', 'ẻ', 'ể', 'ỏ', 'ổ', 'ở', 'ỉ', 'ủ', 'ử', 'ỷ',\n",
    "                   'ã', 'ẵ', 'ẫ', 'ẽ', 'ễ', 'õ', 'ỗ', 'ỡ', 'ĩ', 'ũ', 'ữ', 'ỹ']\n",
    "    }\n",
    "    \n",
    "    for char in word.lower():\n",
    "        if char in vowels['even']:\n",
    "            return 'even'\n",
    "        elif char in vowels['uneven']:\n",
    "            return 'uneven'\n",
    "    return 'even'  # mặc định nếu không tìm thấy\n",
    "\n",
    "def get_specific_tone(word):\n",
    "    \"\"\"Phân loại thanh điệu cụ thể (ngang/huyền)\"\"\"\n",
    "    huyen_vowels = ['à', 'ằ', 'ầ', 'è', 'ề', 'ò', 'ồ', 'ờ', 'ì', 'ù', 'ừ', 'ỳ']\n",
    "    khong_dau_vowels = ['a', 'ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'i', 'u', 'ư', 'y']\n",
    "    \n",
    "    for char in word.lower():\n",
    "        if char in huyen_vowels:\n",
    "            return 'huyen'\n",
    "        elif char in khong_dau_vowels:\n",
    "            return 'ngang'\n",
    "    return None\n",
    "\n",
    "def check_rhyme(word1, word2):\n",
    "    \"\"\"Kiểm tra vần của hai từ\"\"\"\n",
    "    # Implement rhyme checking logic here\n",
    "    # This is a simplified version\n",
    "    return word1[-1] == word2[-1]\n",
    "\n",
    "def generate_lucbat(model, tokenizer, prompt, temperature=0.7, device='cpu'):\n",
    "    def get_valid_word(candidates, position, line_type, prev_line=None, prev_rhyme=None):\n",
    "        # Quy tắc thanh điệu cho câu lục và câu bát\n",
    "        tone_rules = {\n",
    "            'luc': {\n",
    "                2: 'even',    # Chữ 2: thanh bằng\n",
    "                4: 'uneven',  # Chữ 4: thanh trắc\n",
    "                6: 'even'     # Chữ 6: thanh bằng\n",
    "            },\n",
    "            'bat': {\n",
    "                2: 'even',    # Chữ 2: thanh bằng\n",
    "                4: 'uneven',  # Chữ 4: thanh trắc\n",
    "                6: 'even',    # Chữ 6: thanh bằng\n",
    "                8: 'even'     # Chữ 8: thanh bằng\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for word in candidates:\n",
    "            if not isinstance(word, str) or len(word.strip()) == 0:\n",
    "                continue\n",
    "                \n",
    "            word_tone = get_tone_type(word)\n",
    "            \n",
    "            # Kiểm tra quy tắc thanh điệu theo vị trí\n",
    "            if position in tone_rules[line_type]:\n",
    "                if word_tone != tone_rules[line_type][position]:\n",
    "                    continue\n",
    "            \n",
    "            # Kiểm tra quy tắc vần\n",
    "            if line_type == 'luc' and position == 6:\n",
    "                # Chữ cuối câu lục phải vần với chữ 6 câu bát tiếp theo\n",
    "                if prev_rhyme and not check_rhyme(word, prev_rhyme):\n",
    "                    continue\n",
    "                    \n",
    "            if line_type == 'bat':\n",
    "                if position == 6:\n",
    "                    # Chữ 6 câu bát phải vần với chữ cuối câu lục trước\n",
    "                    if prev_line and not check_rhyme(word, prev_line.split()[-1]):\n",
    "                        continue\n",
    "                elif position == 8:\n",
    "                    # Quy tắc đặc biệt cho chữ 6 và 8 của câu bát\n",
    "                    word6 = prev_line.split()[5] if prev_line else None\n",
    "                    if word6:\n",
    "                        word6_tone = get_specific_tone(word6)\n",
    "                        word8_tone = get_specific_tone(word)\n",
    "                        \n",
    "                        # Nếu chữ 6 thanh ngang thì chữ 8 phải thanh huyền và ngược lại\n",
    "                        if word6_tone == 'ngang' and word8_tone != 'huyen':\n",
    "                            continue\n",
    "                        if word6_tone == 'huyen' and word8_tone != 'ngang':\n",
    "                            continue\n",
    "            \n",
    "            return word\n",
    "        \n",
    "        return candidates[0]  # Trường hợp không tìm được từ phù hợp\n",
    "\n",
    "    model.eval()\n",
    "    lines = []\n",
    "    current_line = prompt.split()\n",
    "    prev_rhyme = None\n",
    "    \n",
    "    # Sinh 4 dòng thơ\n",
    "    for i in range(4):\n",
    "        line_type = 'bat' if i % 2 == 1 else 'luc'\n",
    "        target_length = 8 if line_type == 'bat' else 6\n",
    "        \n",
    "        while len(current_line) < target_length:\n",
    "            input_text = ' '.join(lines + [' '.join(current_line)])\n",
    "            input_ids = torch.tensor(tokenizer.encode(input_text).ids).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                next_token_logits = outputs[0, -1, :] / temperature\n",
    "                \n",
    "                # Lấy nhiều candidates hơn để có nhiều lựa chọn\n",
    "                top_k = 100\n",
    "                top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "                probs = torch.softmax(top_k_logits, dim=-1)\n",
    "                \n",
    "                candidate_indices = top_k_indices[torch.multinomial(probs, num_samples=20)]\n",
    "                candidates = [tokenizer.decode([idx.item()]).strip() for idx in candidate_indices]\n",
    "                \n",
    "                next_word = get_valid_word(\n",
    "                    candidates,\n",
    "                    len(current_line) + 1,\n",
    "                    line_type,\n",
    "                    prev_line=' '.join(current_line) if current_line else None,\n",
    "                    prev_rhyme=prev_rhyme\n",
    "                )\n",
    "                \n",
    "                if next_word:\n",
    "                    current_line.append(next_word)\n",
    "        \n",
    "        lines.append(' '.join(current_line))\n",
    "        if line_type == 'bat':\n",
    "            prev_rhyme = current_line[5]  # Lưu chữ thứ 6 của câu bát\n",
    "        current_line = []\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def check_rhyme(word1, word2):\n",
    "    rhyme1 = get_rhyme(word1)\n",
    "    rhyme2 = get_rhyme(word2)\n",
    "    return rhyme1 == rhyme2\n",
    "\n",
    "def load_and_preprocess_data(file_path: str) -> List[str]:\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df['content'].tolist()\n",
    "\n",
    "def setup_training(texts: List[str], device: torch.device):\n",
    "    tokenizer = create_tokenizer(texts)\n",
    "    dataset = LucBatDataset(texts, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    model = LucBatTransformer(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=6\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    return model, tokenizer, dataloader, optimizer\n",
    "\n",
    "def train_model(texts: List[str], num_epochs: int = 20):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model, tokenizer, dataloader, optimizer = setup_training(texts, device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train_epoch(model, dataloader, optimizer, device)\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss:.4f}')\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_poem(model, tokenizer, prompt: str, num_stanzas: int = 2):\n",
    "    device = next(model.parameters()).device\n",
    "    poem = generate_lucbat(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        temperature=0.8,\n",
    "        device=device,\n",
    "        num_stanzas=num_stanzas\n",
    "    )\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:19:08.666934Z",
     "iopub.status.busy": "2024-11-29T18:19:08.666352Z",
     "iopub.status.idle": "2024-11-29T18:19:08.672265Z",
     "shell.execute_reply": "2024-11-29T18:19:08.671465Z",
     "shell.execute_reply.started": "2024-11-29T18:19:08.666904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"[PAD]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":1, \"content\":\"[UNK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":2, \"content\":\"[CLS]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":3, \"content\":\"[SEP]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":4, \"content\":\"[MASK]\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":5, \"content\":\"\n",
       "\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}], normalizer=None, pre_tokenizer=Whitespace(), post_processor=None, decoder=None, model=WordPiece(unk_token=\"[UNK]\", continuing_subword_prefix=\"##\", max_input_chars_per_word=100, vocab={\"[PAD]\":0, \"[UNK]\":1, \"[CLS]\":2, \"[SEP]\":3, \"[MASK]\":4, \"\n",
       "\":5, \"a\":6, \"b\":7, \"c\":8, \"d\":9, \"e\":10, \"f\":11, \"g\":12, \"h\":13, \"i\":14, \"j\":15, \"k\":16, \"l\":17, \"m\":18, \"n\":19, \"o\":20, \"p\":21, \"q\":22, \"r\":23, \"s\":24, \"t\":25, \"u\":26, \"v\":27, \"x\":28, \"y\":29, \"z\":30, \"à\":31, \"á\":32, \"â\":33, \"ã\":34, \"è\":35, \"é\":36, \"ê\":37, \"ì\":38, \"í\":39, \"ò\":40, \"ó\":41, \"ô\":42, \"õ\":43, \"ù\":44, \"ú\":45, \"ý\":46, \"ă\":47, \"đ\":48, \"ĩ\":49, \"ũ\":50, \"ơ\":51, \"ư\":52, \"ạ\":53, \"ả\":54, \"ấ\":55, \"ầ\":56, \"ẩ\":57, \"ẫ\":58, \"ậ\":59, \"ắ\":60, \"ằ\":61, \"ẳ\":62, \"ẵ\":63, \"ặ\":64, \"ẹ\":65, \"ẻ\":66, \"ẽ\":67, \"ế\":68, \"ề\":69, \"ể\":70, \"ễ\":71, \"ệ\":72, \"ỉ\":73, \"ị\":74, \"ọ\":75, \"ỏ\":76, \"ố\":77, \"ồ\":78, \"ổ\":79, \"ỗ\":80, \"ộ\":81, \"ớ\":82, \"ờ\":83, \"ở\":84, \"ỡ\":85, \"ợ\":86, \"ụ\":87, \"ủ\":88, \"ứ\":89, \"ừ\":90, \"ử\":91, \"ữ\":92, \"ự\":93, \"ỳ\":94, \"ỵ\":95, \"ỷ\":96, \"ỹ\":97, \"##h\":98, ...}))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T18:19:13.382160Z",
     "iopub.status.busy": "2024-11-29T18:19:13.381353Z",
     "iopub.status.idle": "2024-11-30T04:06:11.577075Z",
     "shell.execute_reply": "2024-11-30T04:06:11.575849Z",
     "shell.execute_reply.started": "2024-11-29T18:19:13.382127Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "Training: 100%|██████████| 15668/15668 [29:33<00:00,  8.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:24<00:00,  8.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:24<00:00,  8.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 2.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:22<00:00,  8.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 2.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:18<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 2.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:18<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 2.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:21<00:00,  8.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 2.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:17<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:17<00:00,  8.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:18<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:17<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:19<00:00,  8.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:18<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 2.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:18<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 2.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:18<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:19<00:00,  8.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:20<00:00,  8.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:19<00:00,  8.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:21<00:00,  8.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15668/15668 [29:22<00:00,  8.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 2.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tokenizers.Tokenizer' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m texts \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/poem-vn/new_data_clean2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m train_model(texts, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/lucbat_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Định nghĩa device\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tokenizers.Tokenizer' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "# Đầu tiên load data và train model\n",
    "texts = load_and_preprocess_data('/kaggle/input/poem-vn/new_data_clean2.csv')\n",
    "model, tokenizer = train_model(texts, num_epochs=20)\n",
    "\n",
    "# Save the tokenizer using the save method from the tokenizers library\n",
    "tokenizer.save(\"/kaggle/working/tokenizer.json\")\n",
    "torch.save(model.state_dict(), \"/kaggle/working/lucbat_model.pth\")\n",
    "\n",
    "# Định nghĩa device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Generating\n",
    "prompt = \"thăm con ở trại\"\n",
    "poem = generate_lucbat(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    device=device\n",
    ")\n",
    "print(\"\\nBài thơ được tạo:\")\n",
    "print(poem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== Kích thước của mô hình ===  \n",
    "Vocabulary Size: 12,258 tokens  \n",
    "Embedding Dimension (d_model): 512  \n",
    "Number of Attention Heads: 8  \n",
    "Number of Layers: 6  \n",
    "Feed Forward Dimension: 2048  \n",
    "Dropout Rate: 0.1  \n",
    "\n",
    "Tổng số tham số: 31,478,754  \n",
    "\n",
    "=== Kích thước đầu vào ===\n",
    "Input shape: [batch_size, sequence_length]\n",
    "- Batch size: 16 (mặc định)\n",
    "- Max sequence length: 128 tokens\n",
    "\n",
    "Embedding output shape: [batch_size, sequence_length, d_model]\n",
    "- [16, 128, 512]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:07:58.915301Z",
     "iopub.status.busy": "2024-11-30T04:07:58.914746Z",
     "iopub.status.idle": "2024-11-30T04:07:59.069105Z",
     "shell.execute_reply": "2024-11-30T04:07:59.068220Z",
     "shell.execute_reply.started": "2024-11-30T04:07:58.915268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bài thơ được tạo:\n",
      "thăm con ở trại người duyên\n",
      "mây yêu nhớ nhớ như như trời vào\n",
      "tình đời ta một mình như\n",
      "đã đi người mắt có gió chiều về\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Generating\n",
    "prompt = \"thăm con ở trại\"\n",
    "poem = generate_lucbat(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    device=device\n",
    ")\n",
    "print(\"\\nBài thơ được tạo:\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T04:18:35.088151Z",
     "iopub.status.busy": "2024-11-30T04:18:35.087501Z",
     "iopub.status.idle": "2024-11-30T04:18:35.192817Z",
     "shell.execute_reply": "2024-11-30T04:18:35.192010Z",
     "shell.execute_reply.started": "2024-11-30T04:18:35.088118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bài thơ được tạo:\n",
      "anh đi anh nhớ quê nhà\n",
      "lòng trong người để ngày ngày tiếng sao\n",
      "em xuân yêu để nắng ngày\n",
      "như không biết lại anh anh câu ngày\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Generating\n",
    "prompt = \"anh đi anh nhớ quê nhà\"\n",
    "poem = generate_lucbat(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    device=device\n",
    ")\n",
    "print(\"\\nBài thơ được tạo:\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T09:06:33.820783Z",
     "iopub.status.busy": "2024-11-30T09:06:33.820345Z",
     "iopub.status.idle": "2024-11-30T09:06:34.806471Z",
     "shell.execute_reply": "2024-11-30T09:06:34.805318Z",
     "shell.execute_reply.started": "2024-11-30T09:06:33.820747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mùa xuân ta một là thương\n",
      "chẳng còn như đến như như năm trời\n",
      "hương trăng em nhớ hồng như\n",
      "để lòng đi có em em chờ còn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tokenizers import Tokenizer\n",
    "import re\n",
    "\n",
    "# Định nghĩa lại các class và function cần thiết\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class LucBatTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int = 512, nhead: int = 8, \n",
    "                 num_layers: int = 6, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, \n",
    "                                                  dim_feedforward=2048, \n",
    "                                                  dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        embedded = self.pos_encoder(embedded)\n",
    "        output = self.transformer_encoder(embedded)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc_out(output)\n",
    "        return output\n",
    "\n",
    "def get_rhyme(word):\n",
    "    if not word or not is_vietnamese_word(word):\n",
    "        return ''\n",
    "    vowels = 'aàảãáạăằẳẵắặâầẩẫấậeèẻẽéẹêềểễếệiìỉĩíịoòỏõóọôồổỗốộơờởỡớợuùủũúụưừửữứựyỳỷỹýỵ'\n",
    "    word = word.lower()\n",
    "    rhyme = ''\n",
    "    for i in range(len(word)-1, -1, -1):\n",
    "        if word[i] in vowels:\n",
    "            rhyme = word[i:]\n",
    "            break\n",
    "    return rhyme\n",
    "\n",
    "def is_vietnamese_word(word):\n",
    "    vietnamese_pattern = r'^[aàảãáạăằẳẵắặâầẩẫấậbcdđeèẻẽéẹêềểễếệfghiìỉĩíịjklmnoòỏõóọôồổỗốộơờởỡớợpqrstuùủũúụưừửữứựvwxyỳỷỹýỵz]+$'\n",
    "    return bool(re.match(vietnamese_pattern, word.lower()))\n",
    "\n",
    "def get_tone_type(word):\n",
    "    vowels = {\n",
    "        'even': ['a', 'ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'i', 'u', 'ư', 'y',\n",
    "                'à', 'ằ', 'ầ', 'è', 'ề', 'ò', 'ồ', 'ờ', 'ì', 'ù', 'ừ', 'ỳ'],\n",
    "        'uneven': ['á', 'ắ', 'ấ', 'é', 'ế', 'ó', 'ố', 'ớ', 'í', 'ú', 'ứ', 'ý',\n",
    "                   'ạ', 'ặ', 'ậ', 'ẹ', 'ệ', 'ọ', 'ộ', 'ợ', 'ị', 'ụ', 'ự', 'ỵ',\n",
    "                   'ả', 'ẳ', 'ẩ', 'ẻ', 'ể', 'ỏ', 'ổ', 'ở', 'ỉ', 'ủ', 'ử', 'ỷ',\n",
    "                   'ã', 'ẵ', 'ẫ', 'ẽ', 'ễ', 'õ', 'ỗ', 'ỡ', 'ĩ', 'ũ', 'ữ', 'ỹ']\n",
    "    }\n",
    "    \n",
    "    for char in word.lower():\n",
    "        if char in vowels['even']:\n",
    "            return 'even'\n",
    "        elif char in vowels['uneven']:\n",
    "            return 'uneven'\n",
    "    return 'even'\n",
    "\n",
    "def get_specific_tone(word):\n",
    "    huyen_vowels = ['à', 'ằ', 'ầ', 'è', 'ề', 'ò', 'ồ', 'ờ', 'ì', 'ù', 'ừ', 'ỳ']\n",
    "    khong_dau_vowels = ['a', 'ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'i', 'u', 'ư', 'y']\n",
    "    \n",
    "    for char in word.lower():\n",
    "        if char in huyen_vowels:\n",
    "            return 'huyen'\n",
    "        elif char in khong_dau_vowels:\n",
    "            return 'ngang'\n",
    "    return None\n",
    "\n",
    "def check_rhyme(word1, word2):\n",
    "    rhyme1 = get_rhyme(word1)\n",
    "    rhyme2 = get_rhyme(word2)\n",
    "    return rhyme1 == rhyme2\n",
    "\n",
    "def generate_lucbat(model, tokenizer, prompt, temperature=0.7, device='cpu'):\n",
    "    def get_valid_word(candidates, position, line_type, prev_line=None, prev_rhyme=None):\n",
    "        # Quy tắc thanh điệu cho câu lục và câu bát\n",
    "        tone_rules = {\n",
    "            'luc': {\n",
    "                2: 'even',    # Chữ 2: thanh bằng\n",
    "                4: 'uneven',  # Chữ 4: thanh trắc\n",
    "                6: 'even'     # Chữ 6: thanh bằng\n",
    "            },\n",
    "            'bat': {\n",
    "                2: 'even',    # Chữ 2: thanh bằng\n",
    "                4: 'uneven',  # Chữ 4: thanh trắc\n",
    "                6: 'even',    # Chữ 6: thanh bằng\n",
    "                8: 'even'     # Chữ 8: thanh bằng\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for word in candidates:\n",
    "            if not isinstance(word, str) or len(word.strip()) == 0:\n",
    "                continue\n",
    "                \n",
    "            word_tone = get_tone_type(word)\n",
    "            \n",
    "            # Kiểm tra quy tắc thanh điệu theo vị trí\n",
    "            if position in tone_rules[line_type]:\n",
    "                if word_tone != tone_rules[line_type][position]:\n",
    "                    continue\n",
    "            \n",
    "            # Kiểm tra quy tắc vần\n",
    "            if line_type == 'luc' and position == 6:\n",
    "                # Chữ cuối câu lục phải vần với chữ 6 câu bát tiếp theo\n",
    "                if prev_rhyme and not check_rhyme(word, prev_rhyme):\n",
    "                    continue\n",
    "                    \n",
    "            if line_type == 'bat':\n",
    "                if position == 6:\n",
    "                    # Chữ 6 câu bát phải vần với chữ cuối câu lục trước\n",
    "                    if prev_line and not check_rhyme(word, prev_line.split()[-1]):\n",
    "                        continue\n",
    "                elif position == 8:\n",
    "                    # Quy tắc đặc biệt cho chữ 6 và 8 của câu bát\n",
    "                    word6 = prev_line.split()[5] if prev_line else None\n",
    "                    if word6:\n",
    "                        word6_tone = get_specific_tone(word6)\n",
    "                        word8_tone = get_specific_tone(word)\n",
    "                        \n",
    "                        # Nếu chữ 6 thanh ngang thì chữ 8 phải thanh huyền và ngược lại\n",
    "                        if word6_tone == 'ngang' and word8_tone != 'huyen':\n",
    "                            continue\n",
    "                        if word6_tone == 'huyen' and word8_tone != 'ngang':\n",
    "                            continue\n",
    "            \n",
    "            return word\n",
    "        \n",
    "        return candidates[0]  # Trường hợp không tìm được từ phù hợp\n",
    "\n",
    "    model.eval()\n",
    "    lines = []\n",
    "    current_line = prompt.split()\n",
    "    prev_rhyme = None\n",
    "    \n",
    "    # Sinh 4 dòng thơ\n",
    "    for i in range(4):\n",
    "        line_type = 'bat' if i % 2 == 1 else 'luc'\n",
    "        target_length = 8 if line_type == 'bat' else 6\n",
    "        \n",
    "        while len(current_line) < target_length:\n",
    "            input_text = ' '.join(lines + [' '.join(current_line)])\n",
    "            input_ids = torch.tensor(tokenizer.encode(input_text).ids).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                next_token_logits = outputs[0, -1, :] / temperature\n",
    "                \n",
    "                # Lấy nhiều candidates hơn để có nhiều lựa chọn\n",
    "                top_k = 100\n",
    "                top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "                probs = torch.softmax(top_k_logits, dim=-1)\n",
    "                \n",
    "                candidate_indices = top_k_indices[torch.multinomial(probs, num_samples=20)]\n",
    "                candidates = [tokenizer.decode([idx.item()]).strip() for idx in candidate_indices]\n",
    "                \n",
    "                next_word = get_valid_word(\n",
    "                    candidates,\n",
    "                    len(current_line) + 1,\n",
    "                    line_type,\n",
    "                    prev_line=' '.join(current_line) if current_line else None,\n",
    "                    prev_rhyme=prev_rhyme\n",
    "                )\n",
    "                \n",
    "                if next_word:\n",
    "                    current_line.append(next_word)\n",
    "        \n",
    "        lines.append(' '.join(current_line))\n",
    "        if line_type == 'bat':\n",
    "            prev_rhyme = current_line[5]  # Lưu chữ thứ 6 của câu bát\n",
    "        current_line = []\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# Hàm chính để load model và sinh thơ\n",
    "def load_model_and_generate(model_path, tokenizer_path, prompt):\n",
    "    # Load tokenizer\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "    \n",
    "    # Khởi tạo model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = LucBatTransformer(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=6\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "    \n",
    "    # Sinh thơ\n",
    "    poem = generate_lucbat(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        temperature=0.8,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return poem\n",
    "\n",
    "# Sử dụng\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"/kaggle/input/poem-vn/lucbat_model.pth\"  # Đường dẫn tới file model đã lưu\n",
    "    tokenizer_path = \"/kaggle/input/poem-vn/tokenizer.json\"  # Đường dẫn tới file tokenizer đã lưu\n",
    "    prompt = \"Mùa xuân\"  # Prompt để bắt đầu bài thơ\n",
    "    \n",
    "    poem = load_model_and_generate(model_path, tokenizer_path, prompt)\n",
    "    print(poem)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6061092,
     "sourceId": 10055205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
