{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Kích thước của mô hình ===\n",
      "Vocabulary Size: 12,258 tokens\n",
      "Embedding Dimension (d_model): 512\n",
      "Number of Attention Heads: 8\n",
      "Number of Layers: 6\n",
      "Feed Forward Dimension: 2048\n",
      "Dropout Rate: 0.1\n",
      "\n",
      "Tổng số tham số: 31,478,754\n",
      "\n",
      "=== Kích thước đầu vào ===\n",
      "Input shape: [batch_size, sequence_length]\n",
      "- Batch size: 16 (mặc định)\n",
      "- Max sequence length: 128 tokens\n",
      "\n",
      "Embedding output shape: [batch_size, sequence_length, d_model]\n",
      "- [16, 128, 512]\n",
      "\n",
      "=== Chi tiết các layer ===\n",
      "1. Embedding Layer:\n",
      "   Input: [batch_size, sequence_length]\n",
      "   Output: [batch_size, sequence_length, 512]\n",
      "\n",
      "2. Positional Encoding:\n",
      "   Input: [batch_size, sequence_length, 512]\n",
      "   Output: [batch_size, sequence_length, 512]\n",
      "\n",
      "3. Transformer Encoder:\n",
      "   - Number of layers: 6\n",
      "   - Attention heads per layer: 8\n",
      "   - Feed-forward dimension: 2048\n",
      "   Input: [batch_size, sequence_length, 512]\n",
      "   Output: [batch_size, sequence_length, 512]\n",
      "\n",
      "4. Output Layer:\n",
      "   Input: [batch_size, sequence_length, 512]\n",
      "   Output: [batch_size, sequence_length, 12258]\n",
      "\n",
      "=== Bài thơ được sinh ra ===\n",
      "Mùa xuân sao một con rồi\n",
      "em thu ngày lại mình tình cho tay\n",
      "cho hoa mây chẳng thời tình\n",
      "đi thì mây với xa ra một chờ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tokenizers import Tokenizer\n",
    "import re\n",
    "\n",
    "# Định nghĩa lại các class và function cần thiết\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class LucBatTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int = 512, nhead: int = 8, \n",
    "                 num_layers: int = 6, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, \n",
    "                                                  dim_feedforward=2048, \n",
    "                                                  dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        embedded = self.pos_encoder(embedded)\n",
    "        output = self.transformer_encoder(embedded)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc_out(output)\n",
    "        return output\n",
    "\n",
    "def get_rhyme(word):\n",
    "    if not word or not is_vietnamese_word(word):\n",
    "        return ''\n",
    "    vowels = 'aàảãáạăằẳẵắặâầẩẫấậeèẻẽéẹêềểễếệiìỉĩíịoòỏõóọôồổỗốộơờởỡớợuùủũúụưừửữứựyỳỷỹýỵ'\n",
    "    word = word.lower()\n",
    "    rhyme = ''\n",
    "    for i in range(len(word)-1, -1, -1):\n",
    "        if word[i] in vowels:\n",
    "            rhyme = word[i:]\n",
    "            break\n",
    "    return rhyme\n",
    "\n",
    "def is_vietnamese_word(word):\n",
    "    vietnamese_pattern = r'^[aàảãáạăằẳẵắặâầẩẫấậbcdđeèẻẽéẹêềểễếệfghiìỉĩíịjklmnoòỏõóọôồổỗốộơờởỡớợpqrstuùủũúụưừửữứựvwxyỳỷỹýỵz]+$'\n",
    "    return bool(re.match(vietnamese_pattern, word.lower()))\n",
    "\n",
    "def get_tone_type(word):\n",
    "    vowels = {\n",
    "        'even': ['a', 'ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'i', 'u', 'ư', 'y',\n",
    "                'à', 'ằ', 'ầ', 'è', 'ề', 'ò', 'ồ', 'ờ', 'ì', 'ù', 'ừ', 'ỳ'],\n",
    "        'uneven': ['á', 'ắ', 'ấ', 'é', 'ế', 'ó', 'ố', 'ớ', 'í', 'ú', 'ứ', 'ý',\n",
    "                   'ạ', 'ặ', 'ậ', 'ẹ', 'ệ', 'ọ', 'ộ', 'ợ', 'ị', 'ụ', 'ự', 'ỵ',\n",
    "                   'ả', 'ẳ', 'ẩ', 'ẻ', 'ể', 'ỏ', 'ổ', 'ở', 'ỉ', 'ủ', 'ử', 'ỷ',\n",
    "                   'ã', 'ẵ', 'ẫ', 'ẽ', 'ễ', 'õ', 'ỗ', 'ỡ', 'ĩ', 'ũ', 'ữ', 'ỹ']\n",
    "    }\n",
    "    \n",
    "    for char in word.lower():\n",
    "        if char in vowels['even']:\n",
    "            return 'even'\n",
    "        elif char in vowels['uneven']:\n",
    "            return 'uneven'\n",
    "    return 'even'\n",
    "\n",
    "def get_specific_tone(word):\n",
    "    huyen_vowels = ['à', 'ằ', 'ầ', 'è', 'ề', 'ò', 'ồ', 'ờ', 'ì', 'ù', 'ừ', 'ỳ']\n",
    "    khong_dau_vowels = ['a', 'ă', 'â', 'e', 'ê', 'o', 'ô', 'ơ', 'i', 'u', 'ư', 'y']\n",
    "    \n",
    "    for char in word.lower():\n",
    "        if char in huyen_vowels:\n",
    "            return 'huyen'\n",
    "        elif char in khong_dau_vowels:\n",
    "            return 'ngang'\n",
    "    return None\n",
    "\n",
    "def check_rhyme(word1, word2):\n",
    "    rhyme1 = get_rhyme(word1)\n",
    "    rhyme2 = get_rhyme(word2)\n",
    "    return rhyme1 == rhyme2\n",
    "\n",
    "def generate_lucbat(model, tokenizer, prompt, temperature=0.7, device='cpu'):\n",
    "    def get_valid_word(candidates, position, line_type, prev_line=None, prev_rhyme=None):\n",
    "        # Quy tắc thanh điệu cho câu lục và câu bát\n",
    "        tone_rules = {\n",
    "            'luc': {\n",
    "                2: 'even',    # Chữ 2: thanh bằng\n",
    "                4: 'uneven',  # Chữ 4: thanh trắc\n",
    "                6: 'even'     # Chữ 6: thanh bằng\n",
    "            },\n",
    "            'bat': {\n",
    "                2: 'even',    # Chữ 2: thanh bằng\n",
    "                4: 'uneven',  # Chữ 4: thanh trắc\n",
    "                6: 'even',    # Chữ 6: thanh bằng\n",
    "                8: 'even'     # Chữ 8: thanh bằng\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for word in candidates:\n",
    "            if not isinstance(word, str) or len(word.strip()) == 0:\n",
    "                continue\n",
    "                \n",
    "            word_tone = get_tone_type(word)\n",
    "            \n",
    "            # Kiểm tra quy tắc thanh điệu theo vị trí\n",
    "            if position in tone_rules[line_type]:\n",
    "                if word_tone != tone_rules[line_type][position]:\n",
    "                    continue\n",
    "            \n",
    "            # Kiểm tra quy tắc vần\n",
    "            if line_type == 'luc' and position == 6:\n",
    "                # Chữ cuối câu lục phải vần với chữ 6 câu bát tiếp theo\n",
    "                if prev_rhyme and not check_rhyme(word, prev_rhyme):\n",
    "                    continue\n",
    "                    \n",
    "            if line_type == 'bat':\n",
    "                if position == 6:\n",
    "                    # Chữ 6 câu bát phải vần với chữ cuối câu lục trước\n",
    "                    if prev_line and not check_rhyme(word, prev_line.split()[-1]):\n",
    "                        continue\n",
    "                elif position == 8:\n",
    "                    # Quy tắc đặc biệt cho chữ 6 và 8 của câu bát\n",
    "                    word6 = prev_line.split()[5] if prev_line else None\n",
    "                    if word6:\n",
    "                        word6_tone = get_specific_tone(word6)\n",
    "                        word8_tone = get_specific_tone(word)\n",
    "                        \n",
    "                        # Nếu chữ 6 thanh ngang thì chữ 8 phải thanh huyền và ngược lại\n",
    "                        if word6_tone == 'ngang' and word8_tone != 'huyen':\n",
    "                            continue\n",
    "                        if word6_tone == 'huyen' and word8_tone != 'ngang':\n",
    "                            continue\n",
    "            \n",
    "            return word\n",
    "        \n",
    "        return candidates[0]  # Trường hợp không tìm được từ phù hợp\n",
    "\n",
    "    model.eval()\n",
    "    lines = []\n",
    "    current_line = prompt.split()\n",
    "    prev_rhyme = None\n",
    "    \n",
    "    # Sinh 4 dòng thơ\n",
    "    for i in range(4):\n",
    "        line_type = 'bat' if i % 2 == 1 else 'luc'\n",
    "        target_length = 8 if line_type == 'bat' else 6\n",
    "        \n",
    "        while len(current_line) < target_length:\n",
    "            input_text = ' '.join(lines + [' '.join(current_line)])\n",
    "            input_ids = torch.tensor(tokenizer.encode(input_text).ids).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                next_token_logits = outputs[0, -1, :] / temperature\n",
    "                \n",
    "                # Lấy nhiều candidates hơn để có nhiều lựa chọn\n",
    "                top_k = 100\n",
    "                top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "                probs = torch.softmax(top_k_logits, dim=-1)\n",
    "                \n",
    "                candidate_indices = top_k_indices[torch.multinomial(probs, num_samples=20)]\n",
    "                candidates = [tokenizer.decode([idx.item()]).strip() for idx in candidate_indices]\n",
    "                \n",
    "                next_word = get_valid_word(\n",
    "                    candidates,\n",
    "                    len(current_line) + 1,\n",
    "                    line_type,\n",
    "                    prev_line=' '.join(current_line) if current_line else None,\n",
    "                    prev_rhyme=prev_rhyme\n",
    "                )\n",
    "                \n",
    "                if next_word:\n",
    "                    current_line.append(next_word)\n",
    "        \n",
    "        lines.append(' '.join(current_line))\n",
    "        if line_type == 'bat':\n",
    "            prev_rhyme = current_line[5]  # Lưu chữ thứ 6 của câu bát\n",
    "        current_line = []\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# Hàm chính để load model và sinh thơ\n",
    "def load_model_and_generate(model_path, tokenizer_path, prompt):\n",
    "    # Load tokenizer\n",
    "    tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "    \n",
    "    # Khởi tạo model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = LucBatTransformer(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=6\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "    \n",
    "    # Sinh thơ\n",
    "    poem = generate_lucbat(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        prompt=prompt,\n",
    "        temperature=0.8,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return poem\n",
    "\n",
    "def print_model_dimensions():\n",
    "    # Các thông số cố định của mô hình\n",
    "    vocab_size = 12258  # Kích thước từ điển\n",
    "    d_model = 512      # Kích thước embedding\n",
    "    nhead = 8          # Số attention heads\n",
    "    num_layers = 6     # Số layers\n",
    "    dropout = 0.1      # Tỷ lệ dropout\n",
    "    \n",
    "    # Khởi tạo model\n",
    "    model = LucBatTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Kích thước của mô hình ===\")\n",
    "    print(f\"Vocabulary Size: {vocab_size:,} tokens\")\n",
    "    print(f\"Embedding Dimension (d_model): {d_model}\")\n",
    "    print(f\"Number of Attention Heads: {nhead}\")\n",
    "    print(f\"Number of Layers: {num_layers}\")\n",
    "    print(f\"Feed Forward Dimension: 2048\")  # Giá trị mặc định trong mô hình\n",
    "    print(f\"Dropout Rate: {dropout}\")\n",
    "    \n",
    "    # Tính tổng số tham số\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nTổng số tham số: {total_params:,}\")\n",
    "    \n",
    "    print(\"\\n=== Kích thước đầu vào ===\")\n",
    "    print(\"Input shape: [batch_size, sequence_length]\")\n",
    "    print(\"- Batch size: 16 (mặc định)\")\n",
    "    print(\"- Max sequence length: 128 tokens\")\n",
    "    print(\"\\nEmbedding output shape: [batch_size, sequence_length, d_model]\")\n",
    "    print(f\"- [16, 128, {d_model}]\")\n",
    "    \n",
    "    print(\"\\n=== Chi tiết các layer ===\")\n",
    "    print(\"1. Embedding Layer:\")\n",
    "    print(f\"   Input: [batch_size, sequence_length]\")\n",
    "    print(f\"   Output: [batch_size, sequence_length, {d_model}]\")\n",
    "    \n",
    "    print(\"\\n2. Positional Encoding:\")\n",
    "    print(f\"   Input: [batch_size, sequence_length, {d_model}]\")\n",
    "    print(f\"   Output: [batch_size, sequence_length, {d_model}]\")\n",
    "    \n",
    "    print(\"\\n3. Transformer Encoder:\")\n",
    "    print(f\"   - Number of layers: {num_layers}\")\n",
    "    print(f\"   - Attention heads per layer: {nhead}\")\n",
    "    print(f\"   - Feed-forward dimension: 2048\")\n",
    "    print(f\"   Input: [batch_size, sequence_length, {d_model}]\")\n",
    "    print(f\"   Output: [batch_size, sequence_length, {d_model}]\")\n",
    "    \n",
    "    print(\"\\n4. Output Layer:\")\n",
    "    print(f\"   Input: [batch_size, sequence_length, {d_model}]\")\n",
    "    print(f\"   Output: [batch_size, sequence_length, {vocab_size}]\")\n",
    "\n",
    "\n",
    "# Sử dụng\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"model/lucbat_model.pth\"  # Đường dẫn tới file model\n",
    "    tokenizer_path = \"model/tokenizer.json\"  # Đường dẫn tới file tokenizer\n",
    "    \n",
    "    # In kích thước mô hình\n",
    "    print_model_dimensions()\n",
    "    \n",
    "    # Sinh thơ với prompt\n",
    "    prompt = \"Mùa xuân\"\n",
    "    poem = load_model_and_generate(model_path, tokenizer_path, prompt)\n",
    "    print(\"\\n=== Bài thơ được sinh ra ===\")\n",
    "    print(poem)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
